{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migration Status Spreadsheet Notebook (Part 1)\n",
    "\n",
    "## Overview\n",
    "This notebook generates the data for the migration tracking spreadsheet.\n",
    "\n",
    "## What it does\n",
    "- Extracts migration data from COLIN Extract database\n",
    "- Retrieves filing information from LEAR database  \n",
    "- Merges and exports data to Excel format\n",
    "\n",
    "## Output\n",
    "A formatted Excel spreadsheet tracking corporation migration status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sqlalchemy\n",
    "%pip install dotenv\n",
    "%pip install psycopg2-binary\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and configuration loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError, OperationalError\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CONFIG = {\n",
    "    'batch_size': 5000,\n",
    "    'final_excel_fields': [\n",
    "        'Admin Email', 'Incorporation Number', 'Company Name', 'Type',\n",
    "        'Migration Status', 'Migrated Date', 'Filings Done', 'Last Filing Date'\n",
    "    ],\n",
    "    'excel_export': {\n",
    "        'font_size': 12,\n",
    "        'max_column_width': 50,\n",
    "        'output_dir': os.getenv('EXPORT_OUTPUT_DIR')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = CONFIG['batch_size']\n",
    "FINAL_EXCEL_FIELDS = CONFIG['final_excel_fields']\n",
    "\n",
    "print(\"Libraries imported and configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "\n",
    "Configure database connections for COLIN Extract and LEAR databases using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database configurations successfully.\n"
     ]
    }
   ],
   "source": [
    "DATABASE_CONFIG = {\n",
    "    'colin_extract': {\n",
    "        'username': os.getenv(\"DATABASE_COLIN_EXTRACT_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_COLIN_EXTRACT_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_COLIN_EXTRACT_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_COLIN_EXTRACT_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_COLIN_EXTRACT_NAME\")\n",
    "    },\n",
    "    'lear': {\n",
    "        'username': os.getenv(\"DATABASE_LEAR_USERNAME\"),\n",
    "        'password': os.getenv(\"DATABASE_LEAR_PASSWORD\"),\n",
    "        'host': os.getenv(\"DATABASE_LEAR_HOST\"),\n",
    "        'port': os.getenv(\"DATABASE_LEAR_PORT\"),\n",
    "        'name': os.getenv(\"DATABASE_LEAR_NAME\")\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for db_key, db_config in DATABASE_CONFIG.items():\n",
    "    # Build URI\n",
    "    uri = f\"postgresql://{db_config['username']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['name']}\"\n",
    "    DATABASE_CONFIG[db_key] = {'uri': uri}\n",
    "\n",
    "print(\"Database configurations successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Engines\n",
    "\n",
    "Create and test database connections for all configured databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLIN_EXTRACT database engine created and tested successfully.\n",
      "LEAR database engine created and tested successfully.\n",
      "All database engines ready for use.\n"
     ]
    }
   ],
   "source": [
    "engines = {}\n",
    "\n",
    "for db_key, config in DATABASE_CONFIG.items():\n",
    "    try:\n",
    "        engine = create_engine(config['uri'])\n",
    "        \n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "        \n",
    "        engines[db_key] = engine\n",
    "        print(f\"{db_key.upper()} database engine created and tested successfully.\")\n",
    "    \n",
    "    except OperationalError as e:\n",
    "        print(f\"{db_key.upper()} database connection failed: {e}\")\n",
    "        raise\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"{db_key.upper()} database engine creation failed: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"{db_key.upper()} unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "colin_engine = engines['colin_extract']\n",
    "lear_engine = engines['lear']\n",
    "\n",
    "print(\"All database engines ready for use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Migration Data\n",
    "\n",
    "Query COLIN Extract database to get list of migrated corporations with their details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin_extract_query = \"\"\"\n",
    "SELECT\n",
    "    c.admin_email AS \"Admin Email\",\n",
    "    c.corp_num AS \"Incorporation Number\",\n",
    "    cn.corp_name AS \"Company Name\",\n",
    "    cp.corp_type_cd AS \"Type\",\n",
    "    CASE\n",
    "        WHEN cp.processed_status = 'COMPLETED' THEN 'Migrated'\n",
    "        ELSE cp.processed_status\n",
    "    END AS \"Migration Status\",\n",
    "    cp.create_date::date AS \"Migrated Date\"\n",
    "FROM\n",
    "    corp_processing cp\n",
    "JOIN\n",
    "    corporation c ON cp.corp_num = c.corp_num\n",
    "LEFT JOIN\n",
    "    corp_name cn ON c.corp_num = cn.corp_num \n",
    "        AND cn.corp_name_typ_cd IN ('CO', 'NB')\n",
    "        AND cn.end_event_id IS NULL\n",
    "WHERE\n",
    "    cp.environment = 'prod'\n",
    "    AND cp.processed_status = 'COMPLETED'\n",
    "ORDER BY\n",
    "    cp.create_date DESC;\n",
    "\"\"\"\n",
    "    \n",
    "try:\n",
    "    with colin_engine.connect() as conn:\n",
    "        colin_extract_df = pd.read_sql(colin_extract_query, conn)\n",
    "\n",
    "    if colin_extract_df.empty:\n",
    "        raise ValueError(\"COLIN database query returned empty result\")\n",
    "    \n",
    "    print(f\"Fetched {len(colin_extract_df)} rows from COLIN Extract database.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from COLIN Extract: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(colin_extract_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Filing Data\n",
    "\n",
    "Retrieve and aggregate filing information from LEAR database for migrated corporations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lear_combined_query = \"\"\"\n",
    "SELECT \n",
    "    b.id,\n",
    "    b.identifier,\n",
    "    COALESCE(\n",
    "        STRING_AGG(f.filing_type, ', ' ORDER BY f.filing_type), \n",
    "        ''\n",
    "    ) AS \"Filings Done\",\n",
    "    MAX(f.filing_date)::date AS \"Last Filing Date\"\n",
    "FROM businesses b\n",
    "LEFT JOIN filings f ON b.id = f.business_id \n",
    "    AND f.source = 'LEAR' \n",
    "    AND f.status = 'COMPLETED'\n",
    "WHERE b.identifier = ANY(%(identifiers)s)\n",
    "GROUP BY b.id, b.identifier;\n",
    "\"\"\"\n",
    "\n",
    "corp_nums = colin_extract_df['Incorporation Number'].unique().tolist()\n",
    "batches_identifiers = [corp_nums[i:i + BATCH_SIZE] for i in range(0, len(corp_nums), BATCH_SIZE)]\n",
    "\n",
    "# Execute combined query with batch processing\n",
    "lear_combined_results = []\n",
    "for idx, batch_identifiers in enumerate(batches_identifiers):\n",
    "    if not batch_identifiers:\n",
    "        continue\n",
    "    try:\n",
    "        with lear_engine.connect() as conn:\n",
    "            df = pd.read_sql(\n",
    "                lear_combined_query,\n",
    "                conn,\n",
    "                params={\"identifiers\": batch_identifiers}\n",
    "            )\n",
    "        \n",
    "        lear_combined_results.append(df)\n",
    "        print(f\"Batch {idx+1}: {len(df)} records fetched\")\n",
    "    except Exception as e:\n",
    "        print(f\"Batch {idx+1}/{len(batches_identifiers)} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# Process combied results\n",
    "if lear_combined_results:\n",
    "    lear_combined_df = pd.concat(lear_combined_results, ignore_index=True)\n",
    "    lear_combined_df = lear_combined_df.drop_duplicates('identifier', keep='last')\n",
    "    print(f\"Total combined records fetched: {len(lear_combined_df)}\")\n",
    "else:\n",
    "    lear_combined_df = pd.DataFrame(columns=['id', 'identifier', 'Filings Done', 'Last Filing Date'])\n",
    "\n",
    "# Display results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(lear_combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data\n",
    "\n",
    "Merge COLIN Extract migration data with LEAR filing data into a merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = (colin_extract_df\n",
    "              .merge(lear_combined_df, \n",
    "                     left_on='Incorporation Number', \n",
    "                     right_on='identifier', \n",
    "                     how='left'))\n",
    "    \n",
    "    # Select final fields\n",
    "    merged_df = result[FINAL_EXCEL_FIELDS]\n",
    "    print(f\"Data merged successfully: {len(merged_df)} rows\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error merging data: {e}\")\n",
    "\n",
    "# Display merged results\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Excel\n",
    "\n",
    "Generate formatted Excel file with the merged migration tracking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import Font\n",
    "\n",
    "if merged_df.empty:\n",
    "    raise ValueError(\"Data is empty, cannot export\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(CONFIG['excel_export']['output_dir'], exist_ok=True)\n",
    "\n",
    "# Generate filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "excel_filename = f\"migration_status_{timestamp}.xlsx\"\n",
    "excel_filepath = os.path.join(CONFIG['excel_export']['output_dir'], excel_filename)\n",
    "\n",
    "try:\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "        # Export data\n",
    "        merged_df.to_excel(writer, sheet_name='Migration Status', index=False)\n",
    "        worksheet = writer.sheets['Migration Status']\n",
    "\n",
    "        # Adjust format\n",
    "        for row_num, row in enumerate(worksheet.iter_rows(), 1):\n",
    "            for cell in row:\n",
    "                cell.font = Font(\n",
    "                    size=CONFIG['excel_export']['font_size'], \n",
    "                    bold=(row_num == 1)\n",
    "                )\n",
    "\n",
    "        # Freeze header row\n",
    "        worksheet.freeze_panes = 'A2'\n",
    "        \n",
    "        # Adjust column width\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            \n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if cell.value and len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except (TypeError, AttributeError):\n",
    "                    continue\n",
    "            \n",
    "            adjusted_width = min(max_length + 2, CONFIG['excel_export']['max_column_width'])\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    print(f\"Excel export successful: {excel_filename}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Excel export failed: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
